name: Benchmark

on:
  push:
    branches: [main]
    paths:
      - 'internal/**'
      - 'cmd/**'
      - 'benchmark/**'
      - 'go.mod'
      - 'go.sum'
  pull_request:
    branches: [main]
    paths:
      - 'internal/**'
      - 'cmd/**'
      - 'benchmark/**'
      - 'go.mod'
      - 'go.sum'
  workflow_dispatch:
    inputs:
      questions:
        description: 'Number of questions to run'
        required: false
        default: '20'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'
          cache: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: benchmark/locomo/requirements.txt

      - name: Install Python dependencies
        run: |
          pip install -r benchmark/locomo/requirements.txt
          python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('wordnet')"

      - name: Build ultrathink
        run: make build

      - name: Start ultrathink server
        run: |
          ./ultrathink serve --port 3099 &
          sleep 5
          curl -s http://localhost:3099/api/v1/health || exit 1

      - name: Run benchmark
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          cd benchmark/locomo
          python3 memory_augmented.py \
            --dataset data/locomo-mc10-full.jsonl \
            --output results/benchmark_results.json \
            --max-questions ${{ github.event.inputs.questions || '20' }} \
            --ultrathink-url http://localhost:3099/api/v1

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            benchmark/locomo/results/*.json
            benchmark/locomo/logs/*.json
          retention-days: 30

      - name: Post summary
        run: |
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f benchmark/locomo/results/benchmark_results.json ]; then
            python3 -c "
          import json
          with open('benchmark/locomo/results/benchmark_results.json') as f:
              data = json.load(f)
          results = data.get('results', {})
          correct = sum(1 for r in results.values() if r.get('is_correct'))
          total = len(results)
          accuracy = (correct / total * 100) if total > 0 else 0
          print(f'- **Accuracy**: {accuracy:.1f}% ({correct}/{total})')
          print(f'- **Questions**: {total}')
          " >> $GITHUB_STEP_SUMMARY
          fi
