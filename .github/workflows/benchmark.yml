name: Benchmark

on:
  push:
    branches: [main]
    paths:
      - 'internal/**'
      - 'cmd/**'
      - 'benchmark/**'
      - 'go.mod'
      - 'go.sum'
  workflow_dispatch:
    inputs:
      questions:
        description: 'Number of questions to run'
        required: false
        default: '20'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-go@v5
        with:
          go-version: '1.21'
          cache: true

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: benchmark/locomo/requirements.txt

      - name: Install dependencies and build
        run: |
          pip install -r benchmark/locomo/requirements.txt &
          make build &
          wait
          python -c "import nltk; nltk.download('punkt', quiet=True); nltk.download('punkt_tab', quiet=True); nltk.download('wordnet', quiet=True)"

      - name: Start server and run benchmark
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          ./ultrathink start --port 3099 --background
          sleep 3
          curl -sf http://localhost:3099/api/v1/health || (echo "Server failed to start" && exit 1)

          cd benchmark/locomo
          python3 memory_augmented.py \
            --dataset data/locomo-mc10-full.jsonl \
            --output results/benchmark_results.json \
            --max-questions ${{ github.event.inputs.questions || '20' }} \
            --ultrathink-url http://localhost:3099/api/v1

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: benchmark/locomo/results/*.json
          retention-days: 30

      - name: Summary
        if: always()
        run: |
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          if [ -f benchmark/locomo/results/benchmark_results.json ]; then
            python3 -c "
          import json
          with open('benchmark/locomo/results/benchmark_results.json') as f:
              data = json.load(f)
          results = data.get('results', {})
          correct = sum(1 for r in results.values() if r.get('is_correct'))
          total = len(results)
          accuracy = (correct / total * 100) if total > 0 else 0
          print(f'- **Accuracy**: {accuracy:.1f}% ({correct}/{total})')
          " >> $GITHUB_STEP_SUMMARY
          else
            echo "No results file found" >> $GITHUB_STEP_SUMMARY
          fi
